{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the required libraries first and load data file TwitterHate.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweeter_data = pd.read_csv (\"TwitterHate.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31962, 3), 95886, Index(['id', 'label', 'tweet'], dtype='object'), 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tweeter_data parameters \n",
    "tweeter_data.shape, tweeter_data.size, tweeter_data.columns, tweeter_data.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                 id         label\n",
       " count  31962.000000  31962.000000\n",
       " mean   15981.500000      0.070146\n",
       " std     9226.778988      0.255397\n",
       " min        1.000000      0.000000\n",
       " 25%     7991.250000      0.000000\n",
       " 50%    15981.500000      0.000000\n",
       " 75%    23971.750000      0.000000\n",
       " max    31962.000000      1.000000,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# description of data set \n",
    "tweeter_data.describe(), #tweeter_data.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2242"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_list1 = [tweet for tweet in tweeter_data [\"label\"]]\n",
    "print (len(tweeter_list1))\n",
    "len([i for i in tweeter_list1 if i ==1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13    @user #cnn calls #michigan middle school 'buil...\n",
       "14    no comment!  in #australia   #opkillingbay #se...\n",
       "17                               retweet if you agree! \n",
       "23      @user @user lumpy says i am a . prove it lumpy.\n",
       "Name: tweet, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_hate = tweeter_data[tweeter_data[\"label\"] ==1]\n",
    "tweeter_hate[\"tweet\"][:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Get the tweets into a list for easy text cleanup and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_list = [tweet for tweet in tweeter_data [\"tweet\"]]\n",
    "print (len(tweeter_list))\n",
    "tweeter_list[:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Text cleanup: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize the casing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweeter_list = [tweet.lower() for tweet in tweeter_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' @user when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"@user @user thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Using regular expressions, remove user handles. These begin with '@’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "tweeter_list_1 = []\n",
    "for item in tweeter_list:\n",
    "    tweeter_list_1.append(re.sub (r\"@\\S+\" , '', item))   # also can use  r\"@\\w+\"    \n",
    "tweeter_list_1[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using regular expressions, remove URLs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['  when a father is dysfunctional and is so selfish he drags his kids into his dysfunction.   #run',\n",
       " \"  thanks for #lyft credit i can't use cause they don't offer wheelchair vans in pdx.    #disapointed #getthanked\",\n",
       " '  bihday your majesty',\n",
       " '#model   i love u take with u all the time in urð\\x9f\\x93±!!! ð\\x9f\\x98\\x99ð\\x9f\\x98\\x8eð\\x9f\\x91\\x84ð\\x9f\\x91\\x85ð\\x9f\\x92¦ð\\x9f\\x92¦ð\\x9f\\x92¦  ',\n",
       " ' factsguide: society now    #motivation']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "tweeter_list_2 = []\n",
    "for tweet in tweeter_list_1:\n",
    "    re.sub(r\"http\\S+\", \"\", tweet)\n",
    "    re.sub(r\"www.\\S+\", \"\", tweet)\n",
    "    tweeter_list_2.append(tweet)\n",
    "tweeter_list_2[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using TweetTokenizer from NLTK, tokenize the tweets into individual terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['when',\n",
       " 'a',\n",
       " 'father',\n",
       " 'is',\n",
       " 'dysfunctional',\n",
       " 'and',\n",
       " 'is',\n",
       " 'so',\n",
       " 'selfish',\n",
       " 'he',\n",
       " 'drags',\n",
       " 'his',\n",
       " 'kids',\n",
       " 'into',\n",
       " 'his',\n",
       " 'dysfunction',\n",
       " '.',\n",
       " '#',\n",
       " 'run']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk import sent_tokenize , word_tokenize\n",
    "tweeter_list_3 = []\n",
    "for tweet in tweeter_list_2:\n",
    "    tweeter_list_3.append(word_tokenize(tweet))\n",
    "    \n",
    "tweeter_list_3 [0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bihday', 'majesty']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words(\"english\")\n",
    "tweeter_list_4 = []\n",
    "for tweet in tweeter_list_3:\n",
    "    tweeter_list_4.append([word for word in tweet if word.lower() not in stop_words])\n",
    "\n",
    "\n",
    "tweeter_list_4[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove redundant terms like ‘amp’, ‘rt’, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bihday', 'majesty']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_list_4[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Remove ‘#’ symbols from the tweet while retaining the term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bihday', 'majesty']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_list_5 =[]\n",
    "for tweet in tweeter_list_4:\n",
    "    tweeter_list_5.append([word for word in tweet if word.isalpha() and word not in stop_words])\n",
    "\n",
    "tweeter_list_5 [2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra cleanup by removing terms with a length of 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bihday', 'majesty']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_list_6 =[]\n",
    "for tweet in tweeter_list_5:\n",
    "    tweeter_list_6.append([word for word in tweet if len(word)>1])\n",
    "\n",
    "tweeter_list_6[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check out the top terms in the tweets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First, get all the tokenized terms into one large list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "233164"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_terms = []\n",
    "for tweet in tweeter_list_6:\n",
    "    for word in tweet:\n",
    "        tweeter_terms.append(word)\n",
    "        \n",
    "len(tweeter_terms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the counter and find the 10 most common terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('love', 2735),\n",
       " ('day', 2237),\n",
       " ('amp', 1776),\n",
       " ('happy', 1645),\n",
       " ('time', 1120),\n",
       " ('life', 1116),\n",
       " ('today', 1062),\n",
       " ('like', 1044),\n",
       " ('new', 984),\n",
       " ('thankful', 946)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from collections import Counter\n",
    "word_count = Counter(tweeter_terms)\n",
    "common_words_10 = word_count.most_common(10)\n",
    "common_words_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 10 artists>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X,Y= [],[]\n",
    "[X.append(pair[0]) for pair in common_words_10]\n",
    "[Y.append(pair[1]) for pair in common_words_10]\n",
    "plt.bar(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data formatting for predictive modeling:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join the tokens back to form strings. This will be required for the vectorizers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['father dysfunctional selfish drags kids dysfunction run',\n",
       " 'thanks lyft credit ca use cause offer wheelchair vans pdx disapointed getthanked',\n",
       " 'bihday majesty']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_list_7 = []\n",
    "for tweet in tweeter_list_6:\n",
    "    tweeter_list_7.append(\" \".join (tweet))\n",
    "tweeter_list_7 [:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign x and y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>tweet</th>\n",
       "      <th>refine_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>@user when a father is dysfunctional and is s...</td>\n",
       "      <td>father dysfunctional selfish drags kids dysfun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>@user @user thanks for #lyft credit i can't us...</td>\n",
       "      <td>thanks lyft credit ca use cause offer wheelcha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>bihday your majesty</td>\n",
       "      <td>bihday majesty</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  label                                              tweet  \\\n",
       "0   1      0   @user when a father is dysfunctional and is s...   \n",
       "1   2      0  @user @user thanks for #lyft credit i can't us...   \n",
       "2   3      0                                bihday your majesty   \n",
       "\n",
       "                                        refine_tweet  \n",
       "0  father dysfunctional selfish drags kids dysfun...  \n",
       "1  thanks lyft credit ca use cause offer wheelcha...  \n",
       "2                                     bihday majesty  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweeter_data [\"refine_tweet\"] = tweeter_list_7\n",
    "tweeter_data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tweeter_data[[\"refine_tweet\"]]\n",
    "y = tweeter_data[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31962, 1),\n",
       " (31962,),\n",
       " 2,\n",
       " 1,\n",
       " pandas.core.frame.DataFrame,\n",
       " pandas.core.series.Series)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape , y.shape , X.ndim, y.ndim,  type (X), type(y) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform train_test_split using sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 1), (9589, 1), (22373,), (9589,))"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split (X,y ,test_size = 0.3, random_state = 123)\n",
    "\n",
    "X_train.shape, X_test.shape,  y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We’ll use TF-IDF values for the terms as a feature to get into a vector space model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import TF-IDF vectorizer from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instantiate with a maximum of 5000 terms in your vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=5000,  ngram_range=(1,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit and apply on the train set.\n",
    "\n",
    "### Apply on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tfidf = tfidf.fit_transform (tweeter_data['refine_tweet'])     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31962, 5000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.toarray().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 5000), (9589, 5000), (22373,), (9589,))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split (X_tfidf,y ,test_size = 0.3, random_state = 123)\n",
    "\n",
    "X_train.shape, X_test.shape,  y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<22373x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 144605 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model building: Ordinary Logistic Regression\n",
    "### Instantiate Logistic Regression from sklearn with default parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "LR = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit into the train data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LR.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions for the train and the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = lr.predict (X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 0, ..., 0, 0, 0], dtype=int64),\n",
       " array([0, 0, 0, ..., 0, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_test, y_pred_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation: Accuracy, recall, and f_1 score.\n",
    "### Report the accuracy on the train set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "95.41858490144371"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score = metrics.accuracy_score(y_train, y_pred_train)\n",
    "acc_score*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "94.99426426113254"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_score_test = metrics.accuracy_score(y_test, y_pred_test)\n",
    "acc_score_test*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Report the recall on the train set: decent, high, or low."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score\n",
    "# An F1 score reaches its best value at 1 and worst value at 0. A low F1 score is an indication of both poor precision \n",
    "# and poor recall. Best suited for data imbalance problem and practical problme as consider hormonic mean \n",
    "\n",
    "# for classification accuracy in better parameter best have 100 % accuracy\n",
    "\n",
    "# We have got recall of 0.631 which is good for this model as it's above 0.5. F1 score - F1 Score is the weighted \n",
    "# average of Precision and Recall. Therefore, this score takes both false positives and false negatives into account.\n",
    "# ... Accuracy works best if false positives and false negatives have similar cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4618834080717489"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data set \n",
    "F1_Score = f1_score(y_test, y_pred_test)\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.529168580615526"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For train data sent \n",
    "F1_Score = f1_score(y_train, y_pred_train)\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the f1 score on the train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.30700447093889716"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test data set \n",
    "recall = recall_score(y_test, y_pred_test)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3666454487587524"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for train data set\n",
    "recall = recall_score(y_train, y_pred_train)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looks like you need to adjust the class imbalance, as the model seems to focus on the 0s.\n",
    "### Adjust the appropriate class in the LogisticRegression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling use to address imblance problem\n",
    "#!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check version number\n",
    "import imblearn\n",
    "#print(imblearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define oversampling strategy\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "oversample = RandomOverSampler(sampling_strategy='minority')  # 100 percent oversampling of minority data take place\n",
    "oversample_1 = RandomOverSampler(sampling_strategy=0.5)   # 50 percent oversmapling of minority data take place "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(                                            refine_tweet\n",
       " 0      father dysfunctional selfish drags kids dysfun...\n",
       " 1      thanks lyft credit ca use cause offer wheelcha...\n",
       " 2                                         bihday majesty\n",
       " 3                                   model love take time\n",
       " 4                          factsguide society motivation\n",
       " ...                                                  ...\n",
       " 31957                                      ate isz youuu\n",
       " 31958  see nina turner airwaves trying wrap mantle ge...\n",
       " 31959    listening sad songs monday morning otw work sad\n",
       " 31960    sikh temple vandalised calgary wso condemns act\n",
       " 31961                                       thank follow\n",
       " \n",
       " [31962 rows x 1 columns], 0        0\n",
       " 1        0\n",
       " 2        0\n",
       " 3        0\n",
       " 4        0\n",
       "         ..\n",
       " 31957    0\n",
       " 31958    0\n",
       " 31959    0\n",
       " 31960    1\n",
       " 31961    0\n",
       " Name: label, Length: 31962, dtype: int64)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X , y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset \n",
    "#X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the transform\n",
    "X_over, y_over = oversample.fit_resample(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for X_over and Y_over \n",
    "X_over_train, X_over_test ,y_over_train, y_over_test = train_test_split(X_over, y_over, test_size= 0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 5000), (9589, 5000), (22373,), (9589,))"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41608, 5000), (41608,), (17832, 5000), (17832,))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over_train.shape , y_over_train.shape, X_over_test.shape, y_over_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((41608, 5000), (41608,))"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_over_train.shape, y_over_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train again with the adjustment and evaluate.\n",
    "### Train the model on the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_over_train, y_over_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the outpur for oversmaple train and test and original test set \n",
    "y_over_test_pred = lr.predict (X_over_test)\n",
    "y_over_train_pred = lr.predict (X_over_train)\n",
    "y_pred_new = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the predictions on the train set: accuracy, recall, and f_1 score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "93.8481381785554"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data set \n",
    "accuracy_score = accuracy_score (y_over_test, y_over_test_pred)\n",
    "accuracy_score *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9393621137582224"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data set \n",
    "F1_Score = f1_score(y_over_test, y_over_test_pred)\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9519016191064051"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For train data sent \n",
    "F1_Score = f1_score(y_over_train, y_over_train_pred)\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642324888226528"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test data set \n",
    "recall = recall_score(y_test, y_pred_new)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9632441262672369"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for train data set\n",
    "recall = recall_score(y_over_train, y_over_train_pred)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define undersample strategy\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define undersample strategy\n",
    "undersample_1 = RandomUnderSampler(sampling_strategy=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((31962, 5000), (31962,))"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit and apply the transform\n",
    "X_under, y_under = undersample.fit_resample(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tfidf.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset \n",
    "#X, y = make_classification(n_samples=10000, weights=[0.99], flip_y=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split for X_over and Y_over \n",
    "X_under_train, X_under_test ,y_under_train, y_under_test = train_test_split(X_under, y_under, test_size= 0.3, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((22373, 5000), (9589, 5000), (22373,), (9589,))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3138, 5000), (3138,), (1346, 5000), (1346,))"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_under_train.shape , y_under_train.shape, X_under_test.shape, y_under_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3138, 5000), (3138,))"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_under_train.toarray().shape, y_under_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_under_train, y_under_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the outpur for oversmaple train and test and original test set \n",
    "y_under_test_pred = lr.predict (X_under_test)\n",
    "y_under_train_pred = lr.predict (X_under_train)\n",
    "y_pred_new_under = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.76968796433879"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data set \n",
    "accuracy_score = accuracy_score (y_under_test, y_under_test_pred)\n",
    "accuracy_score *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For test data set as per previus basic case \n",
    "#accuracy_score = accuracy_score(y_test, y_pred_new_under )\n",
    "#accuracy_score *100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8366533864541833"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For test data set \n",
    "F1_Score = f1_score(y_under_test, y_under_test_pred)\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9366355741395948"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For train data sent \n",
    "F1_Score = f1_score(y_under_train, y_under_train_pred)\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9642324888226528"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for test data set \n",
    "recall = recall_score(y_test, y_pred_new)\n",
    "recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9238578680203046"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for train data set\n",
    "recall = recall_score(y_under_train, y_under_train_pred)\n",
    "recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularization and Hyperparameter tuning:\n",
    "### Import GridSearch and StratifiedKFold because of class imbalance.\n",
    "\n",
    "\n",
    " sklearn/ cross_val_score method try various combination of train/ test split, and give output of each spliat as split test score \n",
    " \n",
    "skearn/ cross_validate method same as above but retrun a dictionary having fit time , score time and test score for each split\n",
    "\n",
    "Split stratigies:  K fold, Stratified K fold, Shuffle Split, Stratified Shuffle split . K fold  cross_validation is most common.\n",
    "\n",
    "We generally use Stratified K Fold for classification and K fold for regression type problem \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperparameter tunning: Complex Model have more then hyperparameter with some default values it lead to overfit or underfit\n",
    "\n",
    "data,we can optimize it by doing grid search for hyperparameters. Grid search try all combinations of value given for a \n",
    "\n",
    "hyperparameter and record model performence for these valuse in evaluatoin matrix and keep track of best fit model and \n",
    "\n",
    "hyperparameter.We can try all paramerters by writing loop inside loop for each hyperparameter values.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, ShuffleSplit, StratifiedShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiing without any cross validation:  [0.95150946 0.95150946 0.95244055 0.95071965 0.94931164]\n",
      "Classifiing with KFold cross validation:  [0.95150946 0.95213515 0.95494368 0.94618273 0.94993742]\n",
      "Classifiing with KFold cross validation:  [0.95150946 0.95150946 0.95244055 0.95071965 0.94931164]\n"
     ]
    }
   ],
   "source": [
    "print (\"Classifiing without any cross validation: \" ,cross_val_score(LogisticRegression(), X_tfidf, y, cv=5))\n",
    "print (\"Classifiing with KFold cross validation: \" ,cross_val_score(LogisticRegression(), X_tfidf, y, cv=KFold(n_splits=5)))\n",
    "print (\"Classifiing with KFold cross validation: \" ,cross_val_score(LogisticRegression(), X_tfidf, y, cv=StratifiedKFold(n_splits=5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifiing without any cross validation:  {'fit_time': array([0.26801538, 0.25701475, 0.23901391, 0.21401215, 0.25301456]), 'score_time': array([0.00100017, 0.00099993, 0.00099993, 0.00099993, 0.00099993]), 'test_score': array([0.95150946, 0.95150946, 0.95244055, 0.95071965, 0.94931164])}\n",
      "Classifiing with KFold cross validation:  {'fit_time': array([0.24601388, 0.2430141 , 0.18401051, 0.1960113 , 0.22701311]), 'score_time': array([0.00099993, 0.00200009, 0.00100017, 0.00300002, 0.00200009]), 'test_score': array([0.95150946, 0.95213515, 0.95494368, 0.94618273, 0.94993742])}\n",
      "Classifiing with KFold cross validation:  {'fit_time': array([0.27101564, 0.25201416, 0.24201393, 0.22101235, 0.29901743]), 'score_time': array([0.00200009, 0.0010004 , 0.00099993, 0.00100017, 0.00099993]), 'test_score': array([0.95150946, 0.95150946, 0.95244055, 0.95071965, 0.94931164])}\n"
     ]
    }
   ],
   "source": [
    "print (\"Classifiing without any cross validation: \" ,cross_validate(LogisticRegression(), X_tfidf, y, cv=5))\n",
    "print (\"Classifiing with KFold cross validation: \" ,cross_validate(LogisticRegression(), X_tfidf, y, cv=KFold(n_splits=5)))\n",
    "print (\"Classifiing with KFold cross validation: \" ,cross_validate(LogisticRegression(), X_tfidf, y, cv=StratifiedKFold(n_splits=5)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provide the parameter grid to choose for ‘C’ and ‘penalty’ parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use a balanced class weight while instantiating the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import validation_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1 ........ 0.2\n",
      "l1 ........ 0.4\n",
      "l1 ........ 0.6\n",
      "l1 ........ 0.8\n",
      "l1 ........ 1.0\n",
      "l1 ........ 1.2\n",
      "l1 ........ 1.4\n",
      "l1 ........ 1.6\n",
      "l2 ........ 0.2\n",
      "l2 ........ 0.4\n",
      "l2 ........ 0.6\n",
      "l2 ........ 0.8\n",
      "l2 ........ 1.0\n",
      "l2 ........ 1.2\n",
      "l2 ........ 1.4\n",
      "l2 ........ 1.6\n"
     ]
    }
   ],
   "source": [
    "for penalty in ['l1', 'l2']:\n",
    "    for C in [0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4,1.6]:\n",
    "        print (penalty,\"........\", C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split (X_tfidf,y ,test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split (X_over,y_over ,test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_test, y_train, y_test = train_test_split (X_under,y_undern ,test_size = 0.3, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the parameters with the best recall in cross validation.\n",
    "### Choose ‘recall’ as the metric for scoring.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = recall "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose stratified 4 fold cross validation scheme.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "stratified = StratifiedKFold (n_splits=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit into the train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "penalty:     l1  C :    0.8\n",
      "penalty:     l1  C :    1.0\n",
      "penalty:     l1  C :    1.2\n",
      "penalty:     l1  C :    1.4\n",
      "penalty:     l1  C :    1.6\n",
      "penalty:     l1  C :    1.8\n",
      "penalty:     l1  C :    2.0\n",
      "penalty:     l1  C :    2.2\n",
      "penalty:     l1  C :    3.0\n",
      "penalty:     l1  C :    3.5\n",
      "penalty:     l1  C :    4.5\n",
      "penalty:     l1  C :    4.6\n",
      "penalty:     l1  C :    4.7\n",
      "penalty:     l1  C :    5.5\n",
      "penalty:     l1  C :    10.5\n",
      "penalty:     l2  C :    0.8\n",
      "penalty:     l2  C :    1.0\n",
      "penalty:     l2  C :    1.2\n",
      "penalty:     l2  C :    1.4\n",
      "penalty:     l2  C :    1.6\n",
      "penalty:     l2  C :    1.8\n",
      "penalty:     l2  C :    2.0\n",
      "penalty:     l2  C :    2.2\n",
      "penalty:     l2  C :    3.0\n",
      "penalty:     l2  C :    3.5\n",
      "penalty:     l2  C :    4.5\n",
      "penalty:     l2  C :    4.6\n",
      "penalty:     l2  C :    4.7\n",
      "penalty:     l2  C :    5.5\n",
      "penalty:     l2  C :    10.5\n",
      "Best Score: 0.9528215905177732  best_parameters:  {'penalty': 'l2', 'C': 10.5}\n"
     ]
    }
   ],
   "source": [
    "best_score = 0.0\n",
    "best_parameters = {'penalty' :'l2','C' : 1.5}\n",
    "\n",
    "for penalty in ['l1', 'l2']:\n",
    "    for C in [ 0.8, 1.0, 1.2, 1.4,1.6, 1.8, 2.0, 2.2,3.0,3.5,4.5,4.6,4.7,5.5, 10.5]:\n",
    "        score = cross_val_score (LogisticRegression(penalty= penalty, C= C), X_train, y_train,  cv=StratifiedKFold(n_splits=5), n_jobs=-1).mean()\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_parameters['penalty'], best_parameters ['C'] = penalty, C\n",
    "        print (\"penalty:    \", penalty , \" C :   \" , C)\n",
    "print (\"Best Score:\", best_score, \" best_parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are the best parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9528215905177732  best_parameters:  {'penalty': 'l2', 'C': 10.5}\n"
     ]
    }
   ],
   "source": [
    "print (\"Best Score:\", best_score, \" best_parameters: \", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict and evaluate using the best estimator.\n",
    "### Use the best estimator from the grid search to make predictions on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best  Score: 0.9538470165993719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\10559\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:765: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "lr_best = LogisticRegression (** best_parameters)\n",
    "lr_best.fit(X_train, y_train)\n",
    "\n",
    "print (\"Best  Score:\", lr_best.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred_best = lr_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the recall on the test set for the toxic comments?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_score_best = recall_score (y_test, y_test_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9812507016952958"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_score_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the f_1 score?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1_scpre_best = f1_score (y_test, y_test_pred_best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9550346937660493"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_1_scpre_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#                                                 THE END "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
